{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "\n",
    "from scipy.io.wavfile import read, write\n",
    "from scipy import signal\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy.linalg import inv\n",
    "from helpers import Reconstruct, Viz_Y,SMR,get_mixed_signal,SDR\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import torch\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1 * 60 * 44100\n",
    "end = 7 * 60 * 44100 + 20 * 44100\n",
    "\n",
    "samplerate_s, data_speech = read(\"../DATA/BigDATA-Speech.mp3)\n",
    "speech=data_speech[start:end,0]\n",
    "length=speech.shape[0]/samplerate_s\n",
    "print('Shape of the speech {} ... Length : {:.2f}s ... Sample rate : {}'.format(speech.shape[0],length,samplerate_s))\n",
    "\n",
    "samplerate_m, data_music = read(\"../DATA/BigDATA-Piano.mp3\")\n",
    "music=data_music[start:end,0]\n",
    "length=music.shape[0]/samplerate_m\n",
    "print('Shape of the music {} ... Length : {:.2f}s ... Sample rate : {}'.format(music.shape[0],length,samplerate_m))\n",
    "\n",
    "rate = samplerate_s / 16000\n",
    "\n",
    "\n",
    "fs = 16000\n",
    "start = 9 * 60 * fs + 40 * fs\n",
    "end = 10 * 60 * fs + 10 * fs\n",
    "\n",
    "start = 580 * 44100\n",
    "end = 610 * 44100\n",
    "speech_t=data_speech[start : end,0]\n",
    "music_t = data_music[start:end, 0]\n",
    "\n",
    "\n",
    "speech_t = signal.resample(speech_t,int(speech_t.shape[0]/rate))\n",
    "music_t = signal.resample(music_t,int(music_t.shape[0]/rate))\n",
    "samplerate=int(samplerate_m/rate)\n",
    "length=music_t.shape[0]/samplerate\n",
    "\n",
    "print('Shape of the test {} ... Length : {:.2f}s ... Sample rate : {}'.format(music_t.shape[0],length,samplerate))\n",
    "\n",
    "speech = signal.resample(speech,int(speech.shape[0]/rate))\n",
    "music = signal.resample(music,int(music.shape[0]/rate))\n",
    "\n",
    "\n",
    "print('Downsampled rate = {}'.format(samplerate))\n",
    "\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "speech = butter_lowpass_filter(speech,4000,fs)\n",
    "music = butter_lowpass_filter(music,4000,fs)\n",
    "\n",
    "music_t = butter_lowpass_filter(music_t,4000,fs)\n",
    "speech_t = butter_lowpass_filter(speech_t,4000,fs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
